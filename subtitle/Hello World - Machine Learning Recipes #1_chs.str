1
00:00:00,000 --> 00:00:00,000
Youtube subtitles download by mo.dbxdb.com 

2
00:00:00,000 --> 00:00:02,886
[MUSIC PLAYING]

3
00:00:02,886 --> 00:00:06,726


4
00:00:06,726 --> 00:00:08,100
只需要六行代码就可以

5
00:00:08,100 --> 00:00:10,130
写出你第一个机器学习的程序

6
00:00:10,130 --> 00:00:11,671
我是Josh
Gordon, 今天我将会

7
00:00:11,671 --> 00:00:14,374
带领你写出机器学习的Hello World

8
00:00:14,374 --> 00:00:16,039
在这系列视频的最初几集,

9
00:00:16,039 --> 00:00:17,998
我们会教你怎么从头开始

10
00:00:17,998 --> 00:00:19,079
学习机器学习

11
00:00:19,079 --> 00:00:21,560
首先，我们需要两个开源库,

12
00:00:21,560 --> 00:00:23,706
scikit-learn和TensorFlow.

13
00:00:23,706 --> 00:00:25,330
我们即将使用scikit库

14
00:00:25,330 --> 00:00:27,830
但首先，让我们大概说一下什么是机器学习

15
00:00:27,830 --> 00:00:29,240
以及它的重要性

16
00:00:29,240 --> 00:00:31,198
你可以把机器学习看作

17
00:00:31,198 --> 00:00:32,409
人工智能科学的一个分支

18
00:00:32,409 --> 00:00:35,610
早期的AI程序通常只擅长特定的事

19
00:00:35,610 --> 00:00:37,240
比如说“深蓝”能像顶级棋手一样

20
00:00:37,240 --> 00:00:40,150
下国际象棋，不过它也只会干这个

21
00:00:40,150 --> 00:00:41,780
现在我们想写出一个能解决许多不同问题的

22
00:00:41,780 --> 00:00:45,340
程序而不是对每个问题都写一个不同的程序

23
00:00:45,340 --> 00:00:47,460
AlphaGo是一个很好的例子

24
00:00:47,460 --> 00:00:50,150
As we speak, it's competing
in the World Go Championship.

25
00:00:50,150 --> 00:00:53,740
但是类似的程序也能学会玩Atari游戏

26
00:00:53,740 --> 00:00:55,956
机器学习能把这一切变成可能

27
00:00:55,956 --> 00:00:57,330
它能从样本和经验中

28
00:00:57,330 --> 00:00:59,039
学习到算法

29
00:00:59,039 --> 00:01:00,909
而不是依赖于人为编写的规则

30
00:01:00,909 --> 00:01:02,200
So that's the state-of-the-art.

31
00:01:02,200 --> 00:01:03,750
但是我们今天写的是

32
00:01:03,750 --> 00:01:05,632
一个非常简单的例子

33
00:01:05,632 --> 00:01:07,590
我会给你一个听起来很简单的问题

34
00:01:07,590 --> 00:01:09,662
但是不靠机器学习是解决不了的

35
00:01:09,662 --> 00:01:11,370
你能够写代码来分辨出

36
00:01:11,370 --> 00:01:12,774
苹果和橙子的不同之处吗？

37
00:01:12,774 --> 00:01:15,190
想象一下我叫你写一个程序，
以图像文件作为输入

38
00:01:15,190 --> 00:01:17,069
对其进行一些分析

39
00:01:17,069 --> 00:01:18,650
然后输出水果的类别

40
00:01:18,650 --> 00:01:20,040
你能解决这个问题吗？

41
00:01:20,040 --> 00:01:22,526
你得开始写很多特定的规则

42
00:01:22,526 --> 00:01:23,900
例如你可以编写代码来统计

43
00:01:23,900 --> 00:01:26,316
橙色像素的数量然后和绿色像素

44
00:01:26,316 --> 00:01:27,569
的数量作为比较

45
00:01:27,569 --> 00:01:30,920
这个比例能给你水果种类的提示

46
00:01:30,920 --> 00:01:33,043
这能应付像这种一样简单的图像

47
00:01:33,043 --> 00:01:34,709
但是当你深入研究这个问题

48
00:01:34,709 --> 00:01:37,099
你会发现这个世界是复杂的

49
00:01:37,099 --> 00:01:38,650
你编写的规则也不再适用

50
00:01:38,650 --> 00:01:41,180
How would you write code to
handle black-and-white photos

51
00:01:41,180 --> 00:01:44,480
or images with no apples
or oranges in them at all?

52
00:01:44,480 --> 00:01:46,360
实际上对于你编写的任何规则

53
00:01:46,360 --> 00:01:48,790
我都能找到让它不适用的图像

54
00:01:48,790 --> 00:01:50,310
你需要编写成吨的规则,

55
00:01:50,310 --> 00:01:52,518
而这仅仅是为了辨别出苹果和橙子

56
00:01:52,518 --> 00:01:53,690
图像的不同之处

57
00:01:53,690 --> 00:01:57,390
如果我给你一个新的问题，你又得重新开始

58
00:01:57,390 --> 00:01:59,079
显然我们需要更好的方法

59
00:01:59,079 --> 00:02:00,760
因此我们需要一种算法

60
00:02:00,760 --> 00:02:02,480
能为我们找出其中的规则

61
00:02:02,480 --> 00:02:04,599
让我们不必要人工地写这些规则

62
00:02:04,599 --> 00:02:07,690
为此，我们来编写一个分类器

63
00:02:07,690 --> 00:02:10,360
现在你可以把一个分类器当作一个函数

64
00:02:10,360 --> 00:02:13,160
输入一些数据然后为其分配一个标签

65
00:02:13,160 --> 00:02:14,282
作为输出

66
00:02:14,282 --> 00:02:15,740
例如我有一张图片，想对它进行

67
00:02:15,740 --> 00:02:18,235
分类，判断这是苹果还是橙子

68
00:02:18,235 --> 00:02:20,110
又或者我有一封邮件想对其分类

69
00:02:20,110 --> 00:02:22,039
看是否为垃圾邮件

70
00:02:22,039 --> 00:02:23,690
这种自动写出分类器的技术

71
00:02:23,690 --> 00:02:26,220
被称为有监督学习(supervised learning)

72
00:02:26,220 --> 00:02:29,319
It begins with examples of
the problem you want to solve.

73
00:02:29,319 --> 00:02:31,620
为了用代码实现它，
我们将要使用scikit-learn库

74
00:02:31,620 --> 00:02:34,094
现在，我即将下载这个库

75
00:02:34,094 --> 00:02:35,970
有好几种方法去下载它

76
00:02:35,970 --> 00:02:38,241
但对我来说最简单的就是Anaconda.

77
00:02:38,241 --> 00:02:40,449
Anaconda十分方便的为我们安装完
所有依赖的组件

78
00:02:40,449 --> 00:02:42,440
而且还是跨平台的

79
00:02:42,440 --> 00:02:44,190
时间关系，下载和安装的部分

80
00:02:44,190 --> 00:02:45,776
被跳过了

81
00:02:45,776 --> 00:02:47,150
安装完后你可以测试一下

82
00:02:47,150 --> 00:02:48,608
看看是否能正常使用

83
00:02:48,608 --> 00:02:51,364
新建一个python脚本，然后载入SK learn库

84
00:02:51,364 --> 00:02:53,780
Assuming that worked, that's
line one of our program down,

85
00:02:53,780 --> 00:02:56,145
five to go.

86
00:02:56,145 --> 00:02:57,520
To use supervised
learning, we'll

87
00:02:57,520 --> 00:03:00,280
follow a recipe with
a few standard steps.

88
00:03:00,280 --> 00:03:02,340
Step one is to
collect training data.

89
00:03:02,340 --> 00:03:04,789
These are examples of the
problem we want to solve.

90
00:03:04,789 --> 00:03:06,789
For our problem, we're
going to write a function

91
00:03:06,789 --> 00:03:08,002
to classify a piece of fruit.

92
00:03:08,002 --> 00:03:10,210
For starters, it will take
a description of the fruit

93
00:03:10,210 --> 00:03:11,680
as input and
predict whether it's

94
00:03:11,680 --> 00:03:14,349
an apple or an orange as
output, based on features

95
00:03:14,349 --> 00:03:16,310
like its weight and texture.

96
00:03:16,310 --> 00:03:18,160
To collect our
training data, imagine

97
00:03:18,160 --> 00:03:19,310
we head out to an orchard.

98
00:03:19,310 --> 00:03:21,060
We'll look at different
apples and oranges

99
00:03:21,060 --> 00:03:23,627
and write down measurements
that describe them in a table.

100
00:03:23,627 --> 00:03:25,210
In Machine Learning
these measurements

101
00:03:25,210 --> 00:03:26,650
are called features.

102
00:03:26,650 --> 00:03:28,970
To keep things simple,
here we've used just two--

103
00:03:28,970 --> 00:03:31,650
how much each fruit weighs in
grams and its texture, which

104
00:03:31,650 --> 00:03:33,830
can be bumpy or smooth.

105
00:03:33,830 --> 00:03:35,860
A good feature makes
it easy to discriminate

106
00:03:35,860 --> 00:03:37,960
between different
types of fruit.

107
00:03:37,960 --> 00:03:40,210
Each row in our training
data is an example.

108
00:03:40,210 --> 00:03:42,259
It describes one piece of fruit.

109
00:03:42,259 --> 00:03:44,240
The last column is
called the label.

110
00:03:44,240 --> 00:03:46,257
It identifies what type
of fruit is in each row,

111
00:03:46,257 --> 00:03:47,840
and there are just
two possibilities--

112
00:03:47,840 --> 00:03:49,430
apples and oranges.

113
00:03:49,430 --> 00:03:51,560
The whole table is
our training data.

114
00:03:51,560 --> 00:03:53,069
Think of these as
all the examples

115
00:03:53,069 --> 00:03:55,120
we want the classifier
to learn from.

116
00:03:55,120 --> 00:03:57,660
The more training data you
have, the better a classifier

117
00:03:57,660 --> 00:03:59,310
you can create.

118
00:03:59,310 --> 00:04:01,620
Now let's write down our
training data in code.

119
00:04:01,620 --> 00:04:04,150
We'll use two variables--
features and labels.

120
00:04:04,150 --> 00:04:06,060
Features contains the
first two columns,

121
00:04:06,060 --> 00:04:07,887
and labels contains the last.

122
00:04:07,887 --> 00:04:09,470
You can think of
features as the input

123
00:04:09,470 --> 00:04:13,401
to the classifier and labels
as the output we want.

124
00:04:13,401 --> 00:04:15,650
I'm going to change the
variable types of all features

125
00:04:15,650 --> 00:04:18,980
to ints instead of strings,
so I'll use 0 for bumpy and 1

126
00:04:18,980 --> 00:04:19,937
for smooth.

127
00:04:19,937 --> 00:04:22,269
I'll do the same for our
labels, so I'll use 0 for apple

128
00:04:22,269 --> 00:04:23,740
and 1 for orange.

129
00:04:23,740 --> 00:04:26,300
These are lines two and
three in our program.

130
00:04:26,300 --> 00:04:29,160
Step two in our recipes to
use these examples to train

131
00:04:29,160 --> 00:04:30,440
a classifier.

132
00:04:30,440 --> 00:04:32,350
The type of classifier
we'll start with

133
00:04:32,350 --> 00:04:34,029
is called a decision tree.

134
00:04:34,029 --> 00:04:35,449
We'll dive into
the details of how

135
00:04:35,449 --> 00:04:37,110
these work in a future episode.

136
00:04:37,110 --> 00:04:41,269
But for now, it's OK to think of
a classifier as a box of rules.

137
00:04:41,269 --> 00:04:43,880
That's because there are many
different types of classifier,

138
00:04:43,880 --> 00:04:47,740
but the input and output
type is always the same.

139
00:04:47,740 --> 00:04:49,170
I'm going to import the tree.

140
00:04:49,170 --> 00:04:52,000
Then on line four of our script,
we'll create the classifier.

141
00:04:52,000 --> 00:04:54,459
At this point, it's just
an empty box of rules.

142
00:04:54,459 --> 00:04:56,829
It doesn't know anything
about apples and oranges yet.

143
00:04:56,829 --> 00:04:58,870
To train it, we'll need
a learning algorithm.

144
00:04:58,870 --> 00:05:00,307
If a classifier
is a box of rules,

145
00:05:00,307 --> 00:05:02,139
then you can think of
the learning algorithm

146
00:05:02,139 --> 00:05:04,170
as the procedure
that creates them.

147
00:05:04,170 --> 00:05:06,937
It does that by finding
patterns in your training data.

148
00:05:06,937 --> 00:05:09,269
For example, it might notice
oranges tend to weigh more,

149
00:05:09,269 --> 00:05:11,920
so it'll create a rule saying
that the heavier fruit is,

150
00:05:11,920 --> 00:05:14,269
the more likely it
is to be an orange.

151
00:05:14,269 --> 00:05:16,130
In scikit, the
training algorithm

152
00:05:16,130 --> 00:05:19,315
is included in the classifier
object, and it's called Fit.

153
00:05:19,315 --> 00:05:21,899
You can think of Fit as being
a synonym for "find patterns

154
00:05:21,899 --> 00:05:23,136
in data."

155
00:05:23,136 --> 00:05:24,509
We'll get into
the details of how

156
00:05:24,509 --> 00:05:27,040
this happens under the
hood in a future episode.

157
00:05:27,040 --> 00:05:29,100
At this point, we have
a trained classifier.

158
00:05:29,100 --> 00:05:32,860
So let's take it for a spin and
use it to classify a new fruit.

159
00:05:32,860 --> 00:05:36,036
The input to the classifier is
the features for a new example.

160
00:05:36,036 --> 00:05:37,660
Let's say the fruit
we want to classify

161
00:05:37,660 --> 00:05:39,750
is 150 grams and bumpy.

162
00:05:39,750 --> 00:05:43,870
The output will be 0 if it's an
apple or 1 if it's an orange.

163
00:05:43,870 --> 00:05:46,310
Before we hit Enter and see
what the classifier predicts,

164
00:05:46,310 --> 00:05:47,690
let's think for a sec.

165
00:05:47,690 --> 00:05:51,160
If you had to guess, what would
you say the output should be?

166
00:05:51,160 --> 00:05:53,980
To figure that out, compare
this fruit to our training data.

167
00:05:53,980 --> 00:05:55,630
It looks like it's
similar to an orange

168
00:05:55,630 --> 00:05:57,076
because it's heavy and bumpy.

169
00:05:57,076 --> 00:05:59,160
That's what I'd guess
anyway, and if we hit Enter,

170
00:05:59,160 --> 00:06:01,834
it's what our classifier
predicts as well.

171
00:06:01,834 --> 00:06:03,250
If everything
worked for you, then

172
00:06:03,250 --> 00:06:06,050
that's it for your first
Machine Learning program.

173
00:06:06,050 --> 00:06:08,680
You can create a new
classifier for a new problem

174
00:06:08,680 --> 00:06:10,769
just by changing
the training data.

175
00:06:10,769 --> 00:06:13,009
That makes this approach
far more reusable

176
00:06:13,009 --> 00:06:15,101
than writing new rules
for each problem.

177
00:06:15,101 --> 00:06:17,350
Now, you might be wondering
why we described our fruit

178
00:06:17,350 --> 00:06:19,790
using a table of features
instead of using pictures

179
00:06:19,790 --> 00:06:21,759
of the fruit as training data.

180
00:06:21,759 --> 00:06:23,360
Well, you can use
pictures, and we'll

181
00:06:23,360 --> 00:06:25,120
get to that in a future episode.

182
00:06:25,120 --> 00:06:27,279
But, as you'll see later
on, the way we did it here

183
00:06:27,279 --> 00:06:29,002
is more general.

184
00:06:29,002 --> 00:06:30,959
The neat thing is that
programming with Machine

185
00:06:30,959 --> 00:06:32,028
Learning isn't hard.

186
00:06:32,028 --> 00:06:33,819
But to get it right,
you need to understand

187
00:06:33,819 --> 00:06:35,406
a few important concepts.

188
00:06:35,406 --> 00:06:37,990
I'll start walking you through
those in the next few episodes.

189
00:06:37,990 --> 00:06:40,197
Thanks very much for watching,
and I'll see you then.

190
00:06:40,197 --> 00:06:43,850
[MUSIC PLAYING]

191
00:06:43,850 --> 00:06:52,000
 Subtitles End: mo.dbxdb.com

