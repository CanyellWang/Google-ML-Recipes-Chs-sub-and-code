1
00:00:00,000 --> 00:00:00,000
Youtube subtitles download by mo.dbxdb.com 

2
00:00:00,000 --> 00:00:06,765


3
00:00:06,765 --> 00:00:08,140
只有特征选择的好

4
00:00:08,140 --> 00:00:10,270
才能做出一个好的分类器

5
00:00:10,270 --> 00:00:12,060
也就是说选择一个好的特征

6
00:00:12,060 --> 00:00:14,740
是机器学习中最重要的事情之一

7
00:00:14,740 --> 00:00:17,059
但是好的特征是怎么选取的，我们怎样才能知道？

8
00:00:17,059 --> 00:00:19,400
如果你做的是二元分类

9
00:00:19,400 --> 00:00:21,670
那么很容易在两种东西里

10
00:00:21,670 --> 00:00:23,270
选取一个好的特征。

11
00:00:23,270 --> 00:00:26,100
例如，我们想写一个分类器

12
00:00:26,100 --> 00:00:29,090
来分类两种不同品种的狗

13
00:00:29,090 --> 00:00:30,890
格雷伊猎犬和拉布拉多犬

14
00:00:30,890 --> 00:00:34,090
我们可能会选取两种特征-
小狗的身高

15
00:00:34,090 --> 00:00:35,490
和它们眼睛的颜色

16
00:00:35,490 --> 00:00:38,490
来举个简单的例子
让我们来做几个假设

17
00:00:38,490 --> 00:00:40,930
来简化这个问题。

18
00:00:40,930 --> 00:00:43,049
首先，我们通常认为格雷伊猎犬比

19
00:00:43,049 --> 00:00:44,180
拉布拉多犬高

20
00:00:44,180 --> 00:00:47,020
接着我们假设小狗只有两个颜色的眼睛

21
00:00:47,020 --> 00:00:48,750
-- 蓝色和棕色.

22
00:00:48,750 --> 00:00:50,760
那么我们就会说眼睛的颜色不能决定

23
00:00:50,760 --> 00:00:53,160
小狗的品种

24
00:00:53,160 --> 00:00:55,520
也就意味着第一个特征是有用的

25
00:00:55,520 --> 00:00:57,480
但第二个却不能分辨出什么。

26
00:00:57,480 --> 00:01:01,260
为了弄清这个问题，

27
00:01:01,260 --> 00:01:02,970
我将会建一个小型数据库。

28
00:01:02,970 --> 00:01:04,300
先来看看身高这个特征

29
00:01:04,300 --> 00:01:06,650
你觉得这个特征能起到什么作用

30
00:01:06,650 --> 00:01:08,069
平均而言,格雷伊猎犬往往比拉布拉多高几英寸,

31
00:01:08,069 --> 00:01:11,310
但并非总是如此。

32
00:01:11,310 --> 00:01:13,736
因为所有的事情都存在变数

33
00:01:13,736 --> 00:01:15,110
所以当我们想到一个特征

34
00:01:15,110 --> 00:01:17,620
我们必须考虑如何在数据中

35
00:01:17,620 --> 00:01:19,630
寻找不同的值。

36
00:01:19,630 --> 00:01:22,360
让我们用Python 来变成这个问题。

37
00:01:22,360 --> 00:01:24,440
我创建了一个数量为1000的数据集

38
00:01:24,440 --> 00:01:27,736
其中格雷伊猎犬500只，拉布拉多犬500只。

39
00:01:27,736 --> 00:01:29,069
我将会给每一只小狗一个身高

40
00:01:29,069 --> 00:01:31,500
在这个例子中，我们假设格雷伊猎犬的平均身高是28英寸

41
00:01:31,500 --> 00:01:35,510
拉布拉多犬的平均身高是24。

42
00:01:35,510 --> 00:01:37,563
所有小狗的身高都不是完全一样的

43
00:01:37,563 --> 00:01:39,480
假设它们的身高是正态分布的

44
00:01:39,480 --> 00:01:42,790
将它们一起增加或减掉4英寸。

45
00:01:42,790 --> 00:01:44,660
这样我们就有了两组数据

46
00:01:44,660 --> 00:01:47,200
我们可以将这两组数据在柱状图中表示出来

47
00:01:47,200 --> 00:01:49,520
我将会添加一个参数使得格雷伊猎犬数据为红色

48
00:01:49,520 --> 00:01:51,319
拉布拉多犬的数据为蓝色。

49
00:01:51,319 --> 00:01:53,319
现在我们可以运行脚本。

50
00:01:53,319 --> 00:01:57,459
这个图显示了我们给定的小狗的身高

51
00:01:57,459 --> 00:01:58,959
屏幕上出现了很多数据

52
00:01:58,959 --> 00:02:03,202
让我们来简化一下这些数据
使其看起来更方便

53
00:02:03,202 --> 00:02:05,230
我们从最左边的分布开始说

54
00:02:05,230 --> 00:02:08,599
大约是20英寸的高度

55
00:02:08,599 --> 00:02:11,380
如果我问你这只小狗是

56
00:02:11,380 --> 00:02:13,300
一只拉布拉多还是一只格雷伊猎犬

57
00:02:13,300 --> 00:02:14,180
你将会怎么做

58
00:02:14,180 --> 00:02:16,710
我们可以根据身高来判断这只狗是

59
00:02:16,710 --> 00:02:18,669
某品种的概率有多高

60
00:02:18,669 --> 00:02:20,940
这里看起来这只狗更有可能是一只拉布拉多犬

61
00:02:20,940 --> 00:02:22,967
另一方面
如果我们看到右边的直方图

62
00:02:22,967 --> 00:02:24,550
判断35英寸的狗

63
00:02:24,550 --> 00:02:26,949
的品种

64
00:02:26,949 --> 00:02:29,449
可以非常自信地说,他们是格雷伊猎犬。

65
00:02:29,449 --> 00:02:31,300
那么在直方图中间部分狗的品种呢？

66
00:02:31,300 --> 00:02:33,520
你可以看到，直方图不能给我们提供太多的信息

67
00:02:33,520 --> 00:02:36,750
因为两种狗的概率很接近。

68
00:02:36,750 --> 00:02:40,220
所以高度是很有用的特征，但不是完美的。

69
00:02:40,220 --> 00:02:42,280
这就是为什么在机器学习中

70
00:02:42,280 --> 00:02:43,482
需要收集多样特征

71
00:02:43,482 --> 00:02:45,440
否则你可以直接写一个if语句做判断

72
00:02:45,440 --> 00:02:47,160
而不用写分类器

73
00:02:47,160 --> 00:02:50,590
找出你应该使用什么类型的特征

74
00:02:50,590 --> 00:02:52,389
来做一个思想实验。

75
00:02:52,389 --> 00:02:53,819
解设你就是那个分类器

76
00:02:53,819 --> 00:02:55,870
如果你要分别出一只狗是拉布拉多犬还是格雷伊猎犬

77
00:02:55,870 --> 00:03:00,167
你还需要知道哪些信息？

78
00:03:00,167 --> 00:03:01,750
你可能会问它们毛发的长度

79
00:03:01,750 --> 00:03:04,680
或者奔跑的速度或者体重。

80
00:03:04,680 --> 00:03:06,979
到底要选取多少特征

81
00:03:06,979 --> 00:03:08,550
更多的是一种艺术而非科学。

82
00:03:08,550 --> 00:03:10,720
但作为一个经验法则,想想要有多少个特征

83
00:03:10,720 --> 00:03:12,620
你才能解决这个问题。

84
00:03:12,620 --> 00:03:15,590
现在再来看看另一个特征：眼睛的颜色

85
00:03:15,590 --> 00:03:17,470
来举个简单的例子

86
00:03:17,470 --> 00:03:20,500
假如小狗只有两种颜色的眼睛：蓝色和棕色

87
00:03:20,500 --> 00:03:22,099
我们知道小狗眼睛的颜色

88
00:03:22,099 --> 00:03:24,500
并不是取决于它的品种

89
00:03:24,500 --> 00:03:28,590
这是这个例子的直方图。

90
00:03:28,590 --> 00:03:32,169
对于大多数的值而言，它们的概率是各占50%

91
00:03:32,169 --> 00:03:33,849
所以这个特征并不能告诉我们什么信息。

92
00:03:33,849 --> 00:03:36,110
因为这个特征与小狗的种类无关

93
00:03:36,110 --> 00:03:39,199
在你的训练集中包含这个一组无用的数据

94
00:03:39,199 --> 00:03:41,940
都会影响你的分类器的精度

95
00:03:41,940 --> 00:03:45,210
这是因为有可能影响到一些特例

96
00:03:45,210 --> 00:03:48,430
特别是如果你只有少量的训练数据。

97
00:03:48,430 --> 00:03:50,039


98
00:03:50,039 --> 00:03:52,319
你还希望你的特征是独立的

99
00:03:52,319 --> 00:03:54,599
独立的特征给出

100
00:03:54,599 --> 00:03:56,870
不同类型的信息。

101
00:03:56,870 --> 00:03:59,360
假设在我们的数据集中已经有了一个特征

102
00:03:59,360 --> 00:04:00,800
高度（英寸）

103
00:04:00,800 --> 00:04:02,250
那么增加另一个特征--如高度（厘米）

104
00:04:02,250 --> 00:04:05,800
这个特征是否能起到作用呢？

105
00:04:05,800 --> 00:04:08,229
答案是没用

106
00:04:08,229 --> 00:04:09,410
因为我们已经有一个跟它完全相关的特征

107
00:04:09,410 --> 00:04:12,650
从你的训练集中去除掉相关性很高的特征

108
00:04:12,650 --> 00:04:14,032
是个很不错的做法

109
00:04:14,032 --> 00:04:15,490
这是因为许多的分类器

110
00:04:15,490 --> 00:04:18,190
还不能意识到用英寸表示的高度和

111
00:04:18,190 --> 00:04:20,199
用厘米表示的高度是同一个东西。

112
00:04:20,199 --> 00:04:23,339
因此他们可能会重复计算这一特性。

113
00:04:23,339 --> 00:04:26,600
最后，我们想要选取的特征能够易于理解。

114
00:04:26,600 --> 00:04:28,730
举个例子，

115
00:04:28,730 --> 00:04:30,329
在两个不同的城市间传递一封信

116
00:04:30,329 --> 00:04:33,579
将要花多少天的时间

117
00:04:33,579 --> 00:04:37,130
两个城市间的距离越远，信的传输时间就越久

118
00:04:37,130 --> 00:04:39,649
最好的特征就是

119
00:04:39,649 --> 00:04:42,199
利用两个城市间的距离

120
00:04:42,199 --> 00:04:44,220
比较差的两个特征就是


121
00:04:44,220 --> 00:04:47,160
给定城市位置

122
00:04:47,160 --> 00:04:48,259
的纬度和经度。

123
00:04:48,259 --> 00:04:48,259
原因就是

124
00:04:48,970 --> 00:04:51,120
根据两个城市间的距离

125
00:04:51,120 --> 00:04:54,100
很容易猜测信要花多久的时间到达

126
00:04:54,100 --> 00:04:56,880
但是要学习纬度和经度之间的关系

127
00:04:56,880 --> 00:05:00,019
需要花更多的时间
而且你的训练集中

128
00:05:00,019 --> 00:05:01,985
也要更多的数据

129
00:05:01,985 --> 00:05:03,360
现在,有技术可以用来找出

130
00:05:03,360 --> 00:05:05,970
有用的特征,

131
00:05:05,970 --> 00:05:08,920
甚至可以知道哪些特征的组合是最好的。

132
00:05:08,920 --> 00:05:11,389
所以你可以不再根据运气来决定特征的选择。

133
00:05:11,389 --> 00:05:13,769
我们将会在之后的课程中学习到。

134
00:05:13,769 --> 00:05:16,230
下次来,我们将继续为监督学习

135
00:05:16,230 --> 00:05:17,750
建立知识学习。

136
00:05:17,750 --> 00:05:19,680
我们将展示用不同类型的分类器
137
00:05:19,680 --> 00:05:22,290
用来解决相同的问题


138
00:05:22,290 --> 00:05:24,240
进一步深入学习工作原理

139
00:05:24,240 --> 00:05:27,220
谢谢收看，下次见。

140
00:05:27,220 --> 00:05:40,000
 Subtitles End: mo.dbxdb.com

